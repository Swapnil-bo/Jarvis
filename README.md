# ğŸ¤– J.A.R.V.I.S. â€” MacBook Air M1 Edition

> A fully local, voice-activated AI assistant with real-time dashboard, persistent memory, tool automation, and WhatsApp messaging â€” running 100% on Apple Silicon.
> No cloud. No paid APIs. No internet required at runtime.
> Built on a $999 laptop with 8GB RAM.

[![Built with](https://img.shields.io/badge/Built_on-Apple_Silicon_M1-black?logo=apple)](https://apple.com)
[![RAM](https://img.shields.io/badge/RAM-8GB_Unified-blue)](https://apple.com)
[![Models](https://img.shields.io/badge/LLM-Phi--3_Mini_3.8B-green)](https://ollama.com)
[![Cost](https://img.shields.io/badge/API_Cost-$0-brightgreen)](https://github.com)
[![Challenge](https://img.shields.io/badge/100_Days_of-Vibe_Coding-orange)](https://github.com)

---

## ğŸ¬ What It Looks Like

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ J.A.R.V.I.S. DASHBOARD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  STATUS  â”‚  â”‚ CONVERSATION â”‚  â”‚   SYSTEM    â”‚  â”‚
â”‚  â”‚   â—â—â—   â”‚  â”‚              â”‚  â”‚ â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â–ˆâ–ˆâ–ˆâ–ˆ   â”‚  â”‚ YOU: What's  â”‚  â”‚ â”‚78%â”‚ â”‚42%â”‚ â”‚  â”‚
â”‚  â”‚ LISTEN  â”‚  â”‚  the time?   â”‚  â”‚ â”‚BATâ”‚ â”‚RAMâ”‚ â”‚  â”‚
â”‚  â”‚         â”‚  â”‚              â”‚  â”‚ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚ â”Œâ”€â”€â”¬â”€â”€â” â”‚  â”‚ JARVIS: It's â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ â”‚12â”‚ 8â”‚ â”‚  â”‚  3:42 PM,    â”‚  â”‚ TOOL ROUTER â”‚  â”‚
â”‚  â”‚ â”‚EXâ”‚FCâ”‚ â”‚  â”‚  Sonu.       â”‚  â”‚ âš¡ system    â”‚  â”‚
â”‚  â”‚ â””â”€â”€â”´â”€â”€â”˜ â”‚  â”‚              â”‚  â”‚   â†’ time    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                   â”‚
â”‚  J.A.R.V.I.S.  â— SPEAKING    â± 00:05:32  ğŸ™ 12  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Live glassmorphic dashboard** at `http://127.0.0.1:8765` â€” real-time status ring, conversation feed, tool router log, system telemetry, all over WebSocket.

---

## ğŸ¯ What This Is

J.A.R.V.I.S. is a personal AI assistant that runs **entirely on a MacBook Air M1 with 8GB RAM**. Every component â€” wake word detection, speech recognition, language understanding, tool execution, persistent memory, and a real-time dashboard â€” runs locally with aggressive memory optimization.

**This is not a wrapper around ChatGPT.** Every model runs on-device using Apple's Neural Engine and Metal GPU.

### What It Can Do

| Category | Examples |
|----------|---------|
| ğŸ’¬ **Conversation** | Chat naturally with context from past conversations |
| ğŸ• **System Info** | "What time is it?" â€¢ "Battery level?" â€¢ "What day is today?" |
| ğŸ’» **Mac Control** | "Open Safari" â€¢ "Set volume to 50%" â€¢ "Take a screenshot" â€¢ "Lock screen" |
| ğŸŒ **Web Search** | "What's the weather in Mumbai?" â€¢ "Bitcoin price?" â€¢ "Latest AI news?" |
| â° **Reminders** | "Set a timer for 5 minutes" â€¢ "Remind me to call Mom in 10 minutes" |
| ğŸ’¬ **WhatsApp** | "Send a WhatsApp message to Mom saying I'll be late" |
| ğŸ§  **Memory** | Remembers your name, interests, past conversations across sessions |
| ğŸ“Š **Dashboard** | Live glassmorphic UI with status, telemetry, chat feed, tool router |

---

## ğŸ—ï¸ Architecture

```
                          ğŸ¤ MacBook Air Microphone
                                   â”‚
                                   â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Continuous InputStream   â”‚  Zero-gap streaming
                     â”‚   + 85Hz High-Pass Filter  â”‚  Removes fan/AC hum
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Dual Energy Gate         â”‚  avg RMS > 15 AND peak > 80
                     â”‚   (anti-hallucination)     â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚ speech detected
                                  â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Wake Word Detection      â”‚  mlx-whisper base (~140MB)
                     â”‚   "Hey Jarvis" / variants  â”‚  2.5s sliding windows
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚ triggered
                                  â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Speech Recording         â”‚  VAD + min 2s capture
                     â”‚   (same stream, zero gap)  â”‚  High-pass pre-filtered
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚ audio captured
                                  â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Speech-to-Text           â”‚  mlx-whisper small (~240MB)
                     â”‚   (anti-hallucination)     â”‚  Apple Neural Engine
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚ text
                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Two-Stage Tool Router     â”‚
                    â”‚                               â”‚
                    â”‚  Stage 1: Keyword Pre-Filter  â”‚  âš¡ 0ms â€” catches 90%
                    â”‚  Stage 2: Phi-3 Classifier    â”‚  ğŸ§  ~3s  â€” complex cases
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     tool foundâ”‚          â”‚no tool
                               â–¼          â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Tool Execute  â”‚  â”‚  NLU / Brain          â”‚
                    â”‚  system_info   â”‚  â”‚  Phi-3 Mini 3.8B      â”‚
                    â”‚  mac_control   â”‚  â”‚  + Memory Context     â”‚
                    â”‚  web_search    â”‚  â”‚  + Identity Firewall  â”‚
                    â”‚  reminder      â”‚  â”‚  + Post-Processing    â”‚
                    â”‚  whatsapp      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
                           â”‚                      â”‚
                           â–¼                      â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Text-to-Speech (macOS native)   â”‚  Voice: Daniel
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Event Bus â†’ WebSocket â†’ Dashboardâ”‚
                    â”‚   Real-time UI at :8765            â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Real-Time Dashboard

A stunning glassmorphic dashboard powered by FastAPI + WebSocket:

**Design:** Dark mode, `backdrop-blur`, animated gradient orbs, cyan/purple accents, Orbitron + JetBrains Mono fonts.

| Component | What It Shows |
|-----------|--------------|
| **Status Ring** | Animated SVG â€” changes color/speed for idle, listening, thinking, speaking |
| **Conversation Feed** | Live chat bubbles â€” user (cyan) and Jarvis (white), auto-scroll |
| **System Gauges** | Battery % and RAM % with circular SVG gauges, color-coded |
| **Tool Router Feed** | Every tool classification with tool name, action, params, timestamp |
| **Memory Stats** | Conversation count, user facts, tools used |
| **Header Bar** | Uptime, wake count, exchange count, connection status |

**Tech:** Single self-contained HTML file (~550 lines), no build step, no npm, no React. Telemetry pushed every 3s via WebSocket. Auto-reconnect on disconnect.

---

## ğŸ§  Memory System

Persistent memory using **ChromaDB** with sentence-transformer embeddings:

| Feature | How It Works |
|---------|-------------|
| **Conversation History** | Every exchange stored with embeddings. Top 3 most relevant retrieved per query via semantic search. |
| **User Profile** | Auto-extracted facts ("The user is an AI engineer", "The user studies at Brainware University"). Stored as key-value pairs. |
| **Context Injection** | Profile facts + relevant past exchanges injected into Phi-3's system prompt every turn. |
| **Persistence** | Stored at `~/.jarvis/memory/` â€” survives app restarts, accumulates over time. |
| **Identity Firewall** | Every memory line rewritten to "The user: ..." before injection. Prevents Phi-3 from adopting user traits. |

---

## ğŸ”§ Two-Stage Tool Router

Most voice assistants use either keyword matching (brittle) or LLM classification (slow). J.A.R.V.I.S. uses **both**:

### Stage 1: Keyword Pre-Filter (0ms)

Catches 90% of commands instantly with zero LLM calls:

```python
"What time is it?"           â†’ system_info/time      âš¡ instant
"Open Brave"                 â†’ mac_control/open_app   âš¡ instant
"Set volume to 50%"          â†’ mac_control/volume_set  âš¡ instant
"Weather in Mumbai?"         â†’ web_search              âš¡ instant
"Bitcoin price?"             â†’ web_search              âš¡ instant
"Set timer for 5 minutes"    â†’ reminder/timer          âš¡ instant
"Take a screenshot"          â†’ mac_control/screenshot  âš¡ instant
```

Smart app name extraction: `"Can you please open Brave browser for me?"` â†’ `Brave`

### Stage 2: Phi-3 Classification (~3s)

Only called for complex cases needing parameter extraction:

```python
"Send Mom a WhatsApp saying I'll be late"  â†’ whatsapp/send (contact + message)
"Tell me a joke about programming"          â†’ none (conversation)
```

### Why Two Stages?

Phi-3-mini (3.8B) occasionally hallucinates tool names (`macOS System` instead of `mac_control`) or misroutes obvious commands. The keyword pre-filter eliminates this for common patterns while Phi-3 handles the long tail.

---

## ğŸ›¡ï¸ Identity Protection (3 Layers)

Phi-3-mini has a fundamental weakness: it reads memory facts like "aspiring AI engineer" and thinks they describe **itself**. This produces responses like *"As an aspiring AI engineer myself..."*. Three layers prevent this:

| Layer | Where | What It Does |
|-------|-------|-------------|
| **Layer 0** | `nlu.py` â€” before Phi-3 | Identity questions ("Who am I?", "Who are you?") return hardcoded responses. Phi-3 is never called. |
| **Layer 1** | `nlu.py` â€” system prompt | Every memory line rewritten to "The user: ..." with explicit markers: "These facts describe the human, NOT you." |
| **Layer 2** | `nlu.py` â€” post-processing | 30+ poison phrases detected in output ("as an engineer myself", "within Brainware", "quest for knowledge"). If found, entire response replaced. |

---

## ğŸ’¾ Memory Budget

Running on **8GB unified memory** â€” every megabyte is a conscious decision:

| Component | RAM Usage | Device | Purpose |
|-----------|-----------|--------|---------|
| Python + deps | ~200MB | CPU | Minimal dependency footprint |
| Wake word (whisper-base) | ~140MB | Neural Engine | Wake detection in 2.5s windows |
| STT (whisper-small) | ~240MB | Neural Engine | Speech transcription |
| Phi-3 Mini (Ollama) | ~2.3GB | Metal GPU | NLU + tool routing |
| ChromaDB + embeddings | ~130MB | CPU | Persistent vector memory |
| FastAPI dashboard | ~15MB | CPU | Real-time WebSocket UI |
| macOS TTS | ~0MB | System | Native `say` command |
| **Total (peak)** | **~3.0GB / 8GB** | | **~42% usage, 58% headroom** âœ… |

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology | Why |
|-------|-----------|-----|
| Audio Streaming | `sounddevice` InputStream + callback | Zero-gap, continuous capture |
| DSP Filter | 85Hz IIR high-pass (numpy) | Removes fan/AC hum before processing |
| Wake Word | `mlx-whisper` base | STT-based detection (openWakeWord broken on M1) |
| Speech-to-Text | `mlx-whisper` small | Best accuracy-to-size ratio on Neural Engine |
| NLU / Brain | Phi-3 Mini 3.8B via Ollama | Fault-isolated, Metal GPU, Q4 quantized |
| Tool Router | Keyword pre-filter + Phi-3 | 0ms for common commands, LLM for complex |
| Memory | ChromaDB + sentence-transformers | Persistent vector search, ~130MB |
| Dashboard | FastAPI + WebSocket + vanilla HTML | ~15MB, single file, no build step |
| Text-to-Speech | macOS native `say` (Daniel) | Zero RAM, built into the OS |
| Config | YAML | Single source of truth for all parameters |

---

## ğŸš€ Quick Start

### Prerequisites

- macOS with Apple Silicon (M1/M2/M3)
- Python 3.11 (`brew install python@3.11`)
- [Ollama](https://ollama.com) installed and running
- [Homebrew](https://brew.sh)

### Setup

```bash
# Clone
git clone https://github.com/Swapnil-bo/jarvis.git
cd jarvis

# System dependencies
brew install portaudio

# AI brain
ollama pull phi3:mini

# Python environment
python3.11 -m venv venv
source venv/bin/activate
pip install -r requirements-phase1.txt

# Launch
python -m src.main
```

### Usage

1. Wait for **"Jarvis is online and ready, sir."**
2. Open **http://127.0.0.1:8765** for the live dashboard
3. Say **"Hey Jarvis"** (or "Buddy") at normal conversation volume
4. Wait for **"Yes?"**
5. Ask your question or give a command
6. Watch the dashboard update in real-time
7. Repeat

---

## ğŸ“ Project Structure

```
jarvis/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ jarvis_config.yaml              # All tunable parameters
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                         # Entry point â€” voice loop + event bus hooks
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ audio.py                    # Streaming mic + 85Hz high-pass DSP
â”‚   â”‚   â”œâ”€â”€ wake_word.py                # STT-based wake word + dual energy gate
â”‚   â”‚   â”œâ”€â”€ stt.py                      # Speech-to-text (anti-hallucination)
â”‚   â”‚   â”œâ”€â”€ nlu.py                      # NLU + 3-layer identity protection
â”‚   â”‚   â””â”€â”€ tts.py                      # Text-to-speech (macOS native)
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”œâ”€â”€ memory_manager.py           # Orchestrates conversation + profile
â”‚   â”‚   â”œâ”€â”€ conversation_store.py       # ChromaDB conversation history
â”‚   â”‚   â””â”€â”€ user_profile.py             # ChromaDB user fact storage
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ router.py                   # Two-stage router (keyword + Phi-3)
â”‚   â”‚   â”œâ”€â”€ system_info.py              # Time, date, battery
â”‚   â”‚   â”œâ”€â”€ mac_control.py              # Apps, volume, brightness, screenshot, lock
â”‚   â”‚   â”œâ”€â”€ web_search.py               # DuckDuckGo web search
â”‚   â”‚   â”œâ”€â”€ reminder.py                 # Timers and reminders
â”‚   â”‚   â””â”€â”€ whatsapp.py                 # WhatsApp Desktop automation
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â”œâ”€â”€ events.py                   # Thread-safe event bus (queue.Queue)
â”‚   â”‚   â”œâ”€â”€ server.py                   # FastAPI + WebSocket server
â”‚   â”‚   â””â”€â”€ static/
â”‚   â”‚       â””â”€â”€ index.html              # Glassmorphic dashboard UI (~550 lines)
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py                   # YAML config loader
â”‚       â””â”€â”€ logger.py                   # Rich logging + psutil RAM monitoring
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ diagnose_audio.py               # Audio pipeline diagnostic
â”‚   â””â”€â”€ fix_wake_word.py                # Wake word troubleshooter
â”œâ”€â”€ logs/                               # Runtime logs with memory profiling
â”œâ”€â”€ models/                             # Local model weights
â”œâ”€â”€ docs/                               # Architecture notes
â””â”€â”€ requirements-phase1.txt             # Python dependencies
```

---

## ğŸ“‹ Roadmap

- [x] **Phase 1: Voice Core** â€” Wake word â†’ STT â†’ NLU â†’ TTS
  - [x] Continuous streaming audio (zero-gap InputStream)
  - [x] 85Hz high-pass DSP filter
  - [x] Dual-gate wake word detection (avg + peak RMS)
  - [x] Anti-hallucination whisper parameters
  - [x] Fault-isolated NLU via Ollama
  - [x] Mic disconnect auto-recovery
- [x] **Phase 2: Memory & Context** â€” ChromaDB persistent memory
  - [x] Conversation history with semantic search
  - [x] User profile auto-extraction
  - [x] Context injection into NLU prompts
  - [x] Identity confusion firewall (3 layers)
- [x] **Phase 3: Tools & Actions** â€” 5 tool modules
  - [x] System info (time, date, battery)
  - [x] Mac control (apps, volume, brightness, screenshot, lock)
  - [x] Web search (DuckDuckGo)
  - [x] Reminders and timers
  - [x] WhatsApp messaging (Desktop automation)
  - [x] Two-stage router (keyword pre-filter + Phi-3)
- [x] **Phase 4: Visual Dashboard** â€” Real-time glassmorphic UI
  - [x] FastAPI + WebSocket backend
  - [x] Event bus architecture
  - [x] Status ring with state animations
  - [x] System telemetry gauges
  - [x] Live conversation feed
  - [x] Tool router activity log
- [ ] **Phase 5: Vision** â€” Screen OCR and webcam analysis
- [ ] **Phase 6: Code Writing** â€” Autocoding, execution, error loop

---

## ğŸ›¡ï¸ Engineering Decisions

### Why Ollama Stays Separate (Not mlx-lm)
On 8GB, process isolation is a **feature**. If Phi-3 OOMs, only Ollama dies â€” audio stream, wake word, and Python app survive. This is the same architecture Apple uses for Siri.

### Why Two-Stage Routing (Not Just LLM)
Phi-3-mini (3.8B params) is too small to reliably classify every command. It hallucinates tool names (`macOS System`), misroutes weather to `system_info`, and fails on phrasing variations. The keyword pre-filter catches 90% of commands in 0ms with 100% accuracy. Phi-3 handles only the remaining complex cases.

### Why Not Async/Multiprocessing
M1 has one Metal GPU. Whisper and Phi-3 can't run in parallel â€” they'd fight over GPU memory. The pipeline is inherently sequential: don't listen while speaking, don't think while listening.

### Why STT-Based Wake Word (Not openWakeWord)
openWakeWord's embedding model produces dead inference on M1 â€” max confidence 0.000017 across 250 chunks. No Apple Silicon TFLite wheel for Python 3.11. We use whisper-base doing 2.5s sliding window transcription with a dual energy gate instead.

### The Identity Confusion Problem
Small LLMs (3-4B params) can't reliably separate "facts about the user in the system prompt" from "facts about themselves." Phi-3 reads `"The user is an AI engineer"` and responds with `"As an AI engineer myself..."`. Our 3-layer defense (hardcoded shortcuts + memory rewriting + output filtering) is the only reliable solution short of upgrading to a larger model.

### The "Thank You" Hallucination Fix
Whisper hallucinates "Thank you for watching" on silence because `condition_on_previous_text=True` creates feedback loops. Fix: `False`, tighter `compression_ratio_threshold=1.8`, higher `no_speech_threshold=0.5`.

---

## ğŸ’¡ What Makes This Different

| Typical AI Assistant | J.A.R.V.I.S. |
|---------------------|---------------|
| Wraps OpenAI's API | Every model runs on-device |
| Costs $$$/month | $0 after setup |
| Sends voice to cloud | Voice never leaves machine |
| Single-purpose chatbot | 5 tool modules + dashboard + memory |
| No documentation | Every design decision explained |
| Needs 16GB+ RAM | Runs on 8GB with 58% headroom |
| Keyword-only routing | Two-stage: keywords (fast) + LLM (smart) |
| No persistence | ChromaDB memory across sessions |

---

## ğŸ”§ Debugging War Stories

Building a local AI assistant on 8GB taught me things no tutorial covers:

1. **openWakeWord is dead on M1** â€” TFLite has no Apple Silicon wheel. ONNX loads but returns zero confidence. Pivoted to STT-based detection.

2. **`sd.rec()` drops 40% of audio** â€” Each call has ~15ms gaps. Over 3 seconds, speech becomes garbled. Fixed with persistent InputStream + callback queue.

3. **Silence threshold is hardware-specific** â€” Started at 500, then 100, finally 30. MacBook Air M1 mic baseline RMS is ~2-7.

4. **Whisper hallucinates on silence** â€” "Thank you for watching" from fan noise. `condition_on_previous_text=False` is mandatory.

5. **Phi-3 adopts user identity** â€” Reads memory facts and says "as an engineer myself." Required 3-layer identity protection system.

6. **Phi-3 invents tool names** â€” Returns `macOS System` instead of `mac_control`. Keyword pre-filter handles this.

7. **WhatsApp Desktop automation is fragile** â€” Electron app doesn't respond to AppleScript reliably. Required coordinate-based clicking with cliclick.

8. **ChromaDB needs metadata** â€” Adding documents without `metadatas` param causes `NoneType.get()` crashes on retrieval.

9. **YAML multiline strings break on colons** â€” System prompt with colons corrupts config parsing. Use `|` pipe syntax.

10. **Accent handling beats model upgrades** â€” Adding "jalvis" to trigger phrases solved Indian English recognition instantly.

---

## ğŸ¤ About

Built by **Swapnil Hazra** ([@Swapnil-bo](https://github.com/Swapnil-bo)) â€” aspiring AI engineer, student at Brainware University.

Part of the **100 Days of Vibe Coding** challenge. This project proves that useful AI doesn't need a datacenter â€” it can run on a $999 laptop with zero ongoing costs.

â­ **Star this repo** if you think local AI is the future.

---

*Built with â¤ï¸ on Apple Silicon. Every decision documented. Every megabyte justified.*